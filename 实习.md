![1744167428076](C:\Users\jeese\AppData\Roaming\Typora\typora-user-images\1744167428076.png)

科大讯飞·讯飞华中（武汉）有限公司
后端开发实习生 教育BG
2025年02月 - 至今 武汉

**项目描述：**该项目负责新疆喀什地区无纸化教学系统的中间层服务开发，对接前端（学生/教师平板）、课后服务、AI评测系统，优化数据传输与接口封装，保障高延迟网络下的稳定交互。

**主要职责：**

- **中间层服务开发：**负责中间层服务端开发，实现前端与后端基础业务系统之间的数据转换和请求转发。
- **优化网络传输效率：**针对边远地区网络高延迟特性，整体使用请求合并、压缩传输策略（GZIP）和部分传输策略，减少40%网络传输量。
- **试卷处理系统：**参与开发学生试卷处理模块，解析复杂嵌套JSON试卷数据，提取学生答案并实现题目自动批阅（规则引擎匹配），主观题利用ElasticSearch寻找匹配答案。
- **业务数据统计：**开发联考数据聚合接口，利用游标分页进行深度分页优化，支持万级考生成绩实时排名。
- **数据缓存优化：**基于Redis主从架构实现关键数据缓存，减少RPC远程调用次数，优化系统响应速度和稳定性，有效降低跨区域通信压力。
- **服务更新机制：**遵从导师的双版本更新策略：小版本（线上热更新）+ 大版本（假期人工部署），保障教学期间服务零中断。



首先这个项目其实就是整合讯飞之前已有的一些功能，比如说语音AI识别给出评分，还有课后处理（不只服务于无纸教学还有新高考什么的）。然后对接前端。特殊基于新疆地区的教学服务需要进行转换为标准的格式，调用后面的基础服务。相当于是个大的解耦项目，大适配器。同时为了增加新的功能，也要在最后课后写新的接口来支持功能。

首先的话，整体项目一共有好几个端，第一就是学生终端，也就是平板，包括答题什么线上试卷都会通过平板来进行发布，然后来做，然后就是学校服务器端这个主要是用来边缘计算，以及做一些比较重的东西的缓存，比如说试卷，教案，课本，课件，以及根据这些处理一些基本的简单操作，剩余比较复杂的操作，网关统一转发到武汉的中间层服务来进行处理。

因为新疆距离武汉距离很遥远，大概2000公里，所以网络传输时间很大，严格限制包的数量和请求次数，所以进行了一些优化，比如说请求合并也就是在学校主机端收到学生端平板的请求固定时间窗口多个相同的请求会合并，然后再进行转发，第二就是数据压缩，主要通过Springboot开启那个压缩，同时学校集群端。也就是前端部分只会存储部分数据，另外一部分在武汉中间层服务，也就是部分传递，在武汉进行完整补全，然后再调用基础服务，比如说课后来进行完整处理。

具体的话我参与的就是跟随我实习的mentor来进行处理试卷处理模块，一个试卷上传请求是个很大的JSON对象，包括用户信息ID和试卷信息ID，试卷分层次，有大题和小题，都是不同的ID，进行反序列化拆包时根据试卷ID需要匹配不同科目试卷它的嵌套规则来进行实现不同的反序列化接口，然后再根据ID数据库中查找对应信息添加上完整的信息之后封装为更大的JSON对象，通过调用课后服务提供的接口，然后课后的话提取学生答案，根据规则引擎说白了就是一大堆if else来进行简单的快速客观题进行评分，主观题利用ElasticSearch寻找匹配答案然后将原始答案和寻找到的答案输入到 Ai部门提供的语义分析匹配度接口之中得到分数，同样根据脚本配置的规则引擎来返回推荐打分并记录，最后一个完整的试卷JSON对象完成，然后持久化到MongoDB，预处理这部分也就是我来做的。

老师去批改主观题的接口不是我做的，但是我看过相关逻辑，是按照题目来进行批改，给出分数后，又会通过中间层根据题ID存储评阅分数课后，以后再去查看的时候，就是完整的，客观题，主观题都打完分了，包括批阅的备注什么的信息全部都有，最终这个JSON非常大，层次很多。



对于服务的更新机制，主要面向新疆地区学校的边缘节点，支持多层次的动态管理与更新策略：

- **配置级热更新**：对于简单的参数或功能开关调整，使用 **Nacos 配置中心** 实现热更新，无需重启服务。
- **蓝绿发布机制**：当更新涉及 **新增方法或类结构变更** 时，我们采用 **蓝绿发布** 的方式。当前运行版本作为 Blue 环境，更新版本部署为 Green 环境，通过网关配置进行调试与灰度测试；再通过 **Nacos 动态修改 Spring Cloud Gateway 的断言路由规则**，将部分或全部流量切换至 Green 服务，实现无感知上线或快速回滚。
- **线下部署场景**：对于涉及系统级更新或大版本升级，尤其在边缘节点网络条件不佳或设备资源有限时，我们仍保留 **线下人工部署机制**，确保更新操作的稳定性与可控性。



然后业务数据的话，我现在在做的就是关于各学校联考的那个整体排名，学生的试卷被老师批改完成然后就会提交，然后学生的成绩会被插入到表中，需要查排名时使用的是浮标滚动分页（where Score > last_Score limit 100）减少分页损耗时将查询结果缓存在Redis中减少RPC调用的次数以及可以通过主从复制同步到学校的从Redis长距离传输的需求，针对全排名，校级别年级排名，班排名，根据字段筛选即可。



**Q：总结你实习的工作内容、业务流程和成果？**

最初的话，首先了解业务，然后处理较为简单的中间层服务，这个服务作为前后端桥梁，处理数据转换与请求转发，确保新疆地区与武汉服务的稳定交互。关于学校端的边缘计算节点针对高延迟网络，设计请求合并、GZIP压缩、部分传输策略，减少40%网络流量。

然后就是试卷处理模块，将学校端传过来的JSON试卷数据，反序列化解析补全信息。

然后我逐渐熟悉业务之后就进入了课后服务的开发，实现客观题规则引擎批阅与主观题ElasticSearch答案匹配。

开发游标分页接口（`WHERE score > last_score LIMIT`），支持万级考生实时排名，结合Redis缓存降低RPC调用等。



整体的服务流程，

1. 学生平板发起请求，新疆边缘节点缓存静态资源并合并/压缩请求，转发至武汉中间层。
2. 中间层补全数据后调用基础服务（如课后服务、AI评测），返回结果经压缩后回传至平板。
3. 试卷处理时，动态解析科目特异性JSON结构，批阅结果持久化后供教师端查询。
4. 联考成绩入库后，通过游标分页与Redis缓存实现高效排名统计。



**Q：为什么用这些技术？**

- **GZIP压缩 & 请求合并**：针对2000+公里跨区域高延迟，减少数据包数量与体积。
- **Redis主从架构**：缓存高频查询数据（如试卷模板、成绩排名），降低跨区域RPC调用耗时。
- **游标分页**：避免传统分页`OFFSET`深度翻页的性能瓶颈，适合联考万级数据实时滚动。
- **ElasticSearch**：利用分词与相似度检索，快速匹配主观题答案（如文科开放题）。



**Q：你用了gzip，那他压缩算法原理你懂吗？**

我对Gzip底层的压缩算法原理了解不算特别深入，但我知道它结合了两种经典的压缩算法：

- **DEFLATE算法：** 这是Gzip的核心。DEFLATE算法本身又结合了LZ77算法和哈夫曼编码（Huffman Coding）。
- **LZ77：** 它通过查找重复出现的字符串序列，并用一个指向之前出现位置的引用（距离和长度）来替换，从而实现压缩。这对于文本或有重复模式的数据效果很好。
- **哈夫曼编码：** 在LZ77处理之后，对剩下的数据（包括原始字符和LZ77的引用标记）使用哈夫曼编码。它是一种变长编码方法，给出现频率高的字符分配较短的编码，给出现频率低的字符分配较长的编码，从而进一步压缩数据。 虽然我没有深入研究过源码级别的实现细节，但大致理解它是通过消除冗余（LZ77）和优化编码（哈夫曼）这两个步骤来达到压缩目的的。如果项目中需要更底层的优化，我会去深入学习其具体实现。”



**Q：你还知道其他压缩算法吗？**

A：如果问题确实在于压缩算法本身对特定数据类型的压缩率不高，我会考虑调研并引入其他的压缩算法，比如Brotli（压缩率通常优于Gzip，但压缩时间可能更长）、Zstandard（Facebook开源，压缩/解压速度快，压缩率也不错）等。选择哪种算法需要进行实际测试。



**Q：实习中遇到最困难的问题是什么？怎么解决的？**

我觉得实习中最有挑战性的问题是中间层系统试卷模块的JSON解析问题。具体来说，我们需要处理不同学科的试卷数据，它们都有三级结构：试卷（比如数学）、大题（应用题）和小题（具体小问），但一个学科每一种试卷在具体结构上有差异。

最初的难点是，如果为每种试卷类型都编写对应的反序列化器和POJO对象，代码量会非常大，而且后续维护和扩展都很困难。特别是当新增科目时，几乎要重写一套逻辑。

我的解决方案分三个核心部分：

首先，我使用了自定义反序列化器（默认的反序列化器依赖预先定义的对象，需要大量定义对象结构），不再依赖预先定义的POJO对象。通过使用JsonNode替代POJO，我可以动态读取JSON节点，这样处理起来灵活多了。

其次，我引入了策略模式来处理不同科目的解析逻辑。每个解析器都实现同一个核心接口，接收原始的JSON节点后执行特定科目的解析逻辑。

**最后，我用工厂模式管理这些解析器。具体实现是利用ioc容器自动注入收集解析器类到一个list，然后提供一个bean初始化方法，用一个Map结构来维护解析器注册表，然后再提供一个方法根据传入的试卷类型，工厂会分发到对应的解析器去处理。**

这套方案最大的好处是扩展性强 - 当我们需要支持新的科目时，只需要编写新的解析器并注册到工厂中，完全不需要修改核心逻辑。这大大降低了维护成本，也让代码结构更加清晰。

这个经历让我更深入理解了设计模式在实际项目中的应用价值，特别是当面对复杂业务逻辑时，好的架构设计能极大提升开发效率和代码质量，同时也学习到了序列化和反序列化的一些东西然后引发了我对一些高性能序列化比如说Protobuf的学习。



**Q：你提到使用请求合并和GZIP压缩来优化高延迟网络，能具体说说你的实现方式吗？**

A：**请求合并机制**

“在高延迟、不稳定的边远地区网络环境下，像学生提交答案、教师修改分数这类操作会产生大量小而频繁的HTTP请求。这不仅效率低下，还容易因网络抖动导致失败。针对这个问题，我们设计并实施了一套**请求合并（或称为请求批处理）机制**来进行优化。

- **（实现方式）** 这套机制的核心逻辑部署在学校本地的**边缘服务节点**上：
  1. **本地缓存与聚合：** 边缘服务会拦截发往中间层的特定类型请求（例如，所有提交答案的请求），在本地内存中进行短时间的缓存聚合。
  2. **触发批量发送：** 当缓存的请求数量达到一定阈值（比如10条），或者自上次发送以来超过了一个设定的时间窗口（比如2秒），边缘服务就会将这些缓存的请求打包。
  3. **构建批量请求：** 将多条原始请求的数据（比如多个答案提交DTO）合并成一个JSON数组（`List<DTO>`），作为一个新的、单一的HTTP请求体。
  4. **调用批量接口：** 将这个批量请求发送到我们中间层服务专门提供的批量处理API接口（例如 `/batchSubmitAnswers`）。
  5. **后端解包处理：** 中间层收到批量请求后，会先解析这个JSON数组，然后遍历每一条数据，将其分发到原有的单条请求处理逻辑中去执行，这样可以最大限度地复用现有业务逻辑。
  6. **响应处理：** 边缘服务在发送批量请求后，主要等待中间层返回一个“批量接收成功”的确认响应即可。至于单条数据的处理成功与否，则由中间层服务异步处理并保证其可靠性（例如通过日志、状态同步或失败重试机制）。

这种做法大幅**减少了传输请求数量（降低 QPS）**，有效对抗弱网情况下的频繁连接失败和网络抖动问题。

但是对于需要立即获得结果的请求，比如朗读评测等等那就不能进行压缩合并，像提交等的话就可以进行压缩处理不需要具体响应的就不行。



**GZIP 压缩传输**

除了请求合并，我们还对数据传输进行了压缩优化。在边缘服务端（Spring Boot），我们开启了 GZIP 压缩支持，对 `application/json` 类型的响应自动压缩。GZIP 在 JSON 文本压缩中效果显著，平均可压缩 70%-90% 的传输体积。

例如，原本一个完整答题包为 30KB，压缩后可降至不足 6KB。对于大批量数据上报，如学生答题、音频 base64 编码传输等场景，**传输速度明显加快，资源消耗明显降低**。



**Q：详细讲一讲你的缓存数据优化思路？**

“关于数据缓存优化，我们主要的目标是**提升多维度成绩排名查询的响应速度**，并**减少对后端基础服务的RPC调用次数**，特别是在新疆这种高延迟网络环境下，要有效**降低跨区域（武汉-新疆）的数据传输压力**。

- **（面临的挑战）** 排名查询需求覆盖不同范围：班级（几十人）、年级（上千人）和联考（可能上万人）。数据量差异巨大。如果直接使用Redis ZSet来存储所有排名，对于年级和联考级别很容易产生包含大量成员的‘大Key，这可能导致Redis性能下降甚至阻塞。同时，查询请求主要来自新疆的边缘节点，频繁调用部署在武汉的主服务会导致延迟过高。
- **（采取的策略与行动）** 针对这些挑战，我们设计并实施了一套分层缓存策略，并结合了Redis主从架构：
  1. **小范围排名（班级维度）：** 对于数据量较小的班级排名，我们直接利用了Redis的`Sorted Set (ZSet)`。Key的设计类似`examId:classId:rank`，`Score`是学生分数，`Member`是学生ID或标识。ZSet的特性可以直接满足Top N、成员排名/分数查询等需求，实现简单高效，**在老师修改完试卷之后，这个学生的成绩就添加到对应班级的那个Zset中了。后续并不会进行刷新，因为这个有时效性，一般成绩出来之后他才会查询的高峰期，以后面的话学校几点查不到的话，那我直接转发到武汉这边中间层的话其实是查的数据库，同时的话像排名这种东西的话都是支持导数为Excel的。所以考虑这种情况，其实改完之后它是有添加固定时间的**
  2. 大范围排名（年级/联考维度）：
     - 首先，后端的排名服务本身采用了**游标分页（Cursor Pagination）** 的方式来处理大数据量的查询，避免深度分页带来的性能问题。
     - 其次，为了加速分页查询的响应，我们**没有将整个年级或联考的排名存入单个ZSet**，而是选择**缓存分页查询的结果**。我们使用了Redis的`Hash`结构。Key可以设计为标识排名类型和考试ID（如`rank:type:grade:examId`），`Field`是页码（如`page:1`, `page:2`），`Value`则是该页排名数据的序列化结果（比如一个包含学生排名信息的JSON列表）。这样每次查询特定页时，优先从缓存获取，大大减少了计算量和数据库压力。
  3. **Redis主从架构应用：** 我们在武汉部署了Redis主节点（Master），负责处理所有写操作和作为数据权威源。在新疆的边缘计算节点部署了Redis从节点（Slave），通过主从复制（Replication）与武汉的主节点保持数据同步。新疆本地的服务**只连接从节点进行读操作**。这样，大部分排名查询请求可以直接由本地的从节点服务，显著降低了网络延迟和跨区域通信的压力。如果本地缓存未命中（比如请求一个尚未被缓存的分页），服务会回源到武汉的主服务进行查询，并将结果缓存到本地Redis中（或者由主服务写入后同步过来）。
- **（达成的效果）** 通过这套组合策略：
  - 我们成功**避免了Redis大Key问题**，保障了Redis服务的稳定性。
  - 显著**降低了**各维度排名查询的**响应时间**，尤其是在新疆地区的用户体验得到了改善。
  - 有效**减少了**对武汉后端主服务的**RPC调用**和跨区域网络流量，降低了系统负载和通信成本。”

这个优化版本更侧重于按照“目标-挑战-策略（分点）-架构-效果”的逻辑链条来组织信息，希望能帮助你更清晰地传达你的工作内容和成果。



**Q：你开发的功能实力上线过了吗？**

“我们项目中非常重视服务的连续性，尤其要保障教学期间的零中断。为此，我们遵循了一套双轨制的更新策略，主要是基于更新内容的影响范围和风险来区分处理方式：

1. **常规迭代与小版本更新（实现线上热更新/零停机）：**
   - 对于不涉及重大架构调整或破坏性变更的功能迭代和Bug修复，我们采用了**蓝绿部署（Blue-Green Deployment）** 的模式。
   - **具体流程是：** 生产环境会同时存在两个逻辑上隔离的应用实例集群：当前稳定运行的‘蓝色’集群和用于部署新版本的‘绿色’集群。
   - 当新版本准备好后，我们会将其部署到‘绿色’集群，并进行充分的测试验证。
   - 确认无误后，利用 **Spring Cloud Gateway** 作为API网关，并通过 **Nacos** 配置中心动态更新路由规则，将线上流量**无缝切换**到‘绿色’集群。整个过程用户无感知，实现了零停机更新。旧的‘蓝色’集群会暂时保留一段时间，作为快速回滚的选项，确认稳定后再进行资源回收或更新为下一次的‘绿色’环境。
2. **重大变更与大版本更新（安排在非教学时段）：**
   - 对于涉及复杂或高风险变更的大版本更新，例如需要进行**数据库结构迁移（Schema Change）**、**大规模数据处理**、或者与**后端基础系统有深度耦合的接口改造**（比如你提到的线下试卷扫描、导入题库功能对接等），这类操作难以完全自动化，且潜在风险较高。
   - 为了确保万无一失，这类更新会被安排在**非教学时段（如假期）** 进行。通常会由专门的运维或开发人员**人工介入和监控**整个部署过程，可能包含手动执行脚本、数据校验、分步上线等环节，以最大限度地控制风险，确保数据一致性和系统稳定性。虽然是人工部署，但目标仍然是尽量缩短维护窗口，快速完成更新。

通过这种结合了自动化蓝绿部署和计划性人工部署的策略，我们既保证了日常迭代的敏捷性和服务的连续性，也为重大变更提供了必要的风险控制窗口，有效地支撑了教学业务的稳定运行。”



**Q：ElasticSearch是按照题目来进行匹配的找到这个题目对应的答案？**

A：使用ElasticSearch进行主观题答案处理有两个层面的应用：

1. **查找标准答案**：通过题目描述查找对应的标准/参考答案。这是基础功能，虽然可以用普通数据库实现，但整合在ElasticSearch中保持了系统一致性。



**Q：提取学生答案并实现题目自动批阅（规则引擎匹配），主观题利用ElasticSearch寻找匹配答案，详细展开讲讲这个过程？**

A：把自动批阅流程做到规则配置化，这样不用写一大堆 if/else 判断。大致过程是这样的：

首先，每道题（不论是大题还是小题）都会在 JSON 数据中标明对应的批阅规则，根据中间层处理的json对象每一个三级二级大题（应用题）和小题（具体小问），都标明了批阅规则。比如用一个 `scoreRule` 字段表示。为了避免写固定的逻辑，把规则抽离出来，每条规则对应一个 Groovy 脚本。例如，对于客观题我用“EXACT”规则，其脚本内容简单就是：

```java
return expected == actual
```

只有当学生的答案和标准答案完全一样时才给满分；而对于主观题，我用“SIMILAR”规则，其脚本大致就是：

```java
return similarity >= 0.8 ? 5 : 0
```

| 规则ID  | 脚本内容                          |
| ------- | --------------------------------- |
| EXACT   | `return expected == actual`       |
| SIMILAR | `return similarity >= 0.8 ? 5 :0` |

这里先通过讯飞识别接口把主观题的学生答案转为文本，再通过 ElasticSearch 来计算学生答案与参考答案之间的语义相似度，如果相似度达到 80% 就给基础分（比如5分），否则不给分。

整个流程是：

- 中间层处理完试卷 JSON 后，课后服务看到题目对应的 `scoreRule` 字段。
- 根据这个规则 ID，从配置好的规则库中加载对应的 Groovy 脚本。
- 对客观题，会直接用脚本判断答案是否完全相同；对主观题，先识别文本，再计算答案之间的相似度，然后用脚本返回相应的分值。

这样就实现了一个灵活的自动批阅机制，新增或调整规则时，只需修改相应脚本，而无需动核心代码。



**Q：语音评测需要转换接口怎么做的？**

A：嗯，首先的话前端采集好像用的是比较标准的ACC格式经过压缩减少传输，然后的话边缘的学校机房转发到武汉服务之后，中间层服务会用**FFmpeg 封装库**将其统一 **转码为标准 WAV 格式**，并设置指定的采样率（如 16kHz、单声道），以满足 AI 部门语音评测接口的输入要求。然后再给ai部门提供的接口，然后再返回分数。**评测结果仅在学生客户端临时展示，不做服务端持久化存储。**



**Q：MongoDB和Redis的区别是什么？**

A：文档型数据库，存储 BSON（二进制 JSON）文档。支持复杂的嵌套文档结构和丰富的查询能力。擅长处理大量复杂结构化数据，提供丰富的查询和聚合功能。主要存储介质是磁盘。



**Q：ES倒排索引原理是什么？**
A：ES（Elasticsearch）底层使用Lucene实现倒排索引。它的核心思想是为每个字段建立一个“词项到文档”的映射。具体来说，文本字段会被分词器分成若干个词条，每个词条会记录在哪些文档中出现，以及出现的位置和频率等信息。这样当用户搜索某个词时，ES可以通过倒排索引快速定位包含该词的文档ID列表，从而实现高效全文检索。



**Q：正排索引和倒排索引的区别？**

A：**正排索引 (Forward Index):**

- 以文档ID为索引，文档内容为值
- 结构类似：文档1 → [词语A, 词语B, 词语C...]
- 适合根据文档ID快速获取文档内容
- 不适合全文搜索，因为需要扫描所有文档才能找到包含特定词的文档

**倒排索引 (Inverted Index):**

- 以词语为索引，包含该词语的文档ID列表为值
- 结构类似：词语A → [文档1, 文档3, 文档7...]
- 非常适合全文搜索，可以快速找到包含特定词的所有文档
- Lucene和Elasticsearch的核心索引结构就是倒排索引



**Q：ES有哪些分词器？**

A：分词器是非常重要的结构，因为最终是利用倒排索引来进行检索，所以有5种分词器可以选择。

第1种标准分词器，它是按照Unicode来进行分词的，全部转为小写，而且去掉标点符号，

第2种简单分词器，它是按照非字母字段进行分词，全转为小写。

第3种空格分词器，只要遇到空格就进行分词不转大小写

第4种特定分词，在简单分子基础上还根据某些冠词啊be动词进行分词。

第5种关键词分子器，整个输入作为分词。

还有中文特定的ik分子器，它有两种模式，第1种精确，比如说我爱北京天安门主语和谓语作为分词，然后特有名词也作为分词，然后还有最大模式，最大模式的话，同样也足以谓语作为分词，然后的话名词的话一个大名词，比如说天安门可以称为安门，天安门。这些都作为分词。



**Q：ES有哪些节点？**
A：ES中的节点类型包括：主节点（Master Node）、数据节点（Data Node）、协调节点（Coordinating Node）、客户端节点（Client Node）。其中主节点负责集群管理和状态控制，数据节点负责索引数据的存储与查询，协调节点接收外部请求并转发给对应节点，客户端节点发出请求。



**Q：ES的主节点有多少个？**
A：ES允许配置多个可被选为主节点的节点（通过`node.master: true`设置），但在一个时刻，整个集群中只能有一个主节点。为了保证高可用，通常推荐配置3个master-eligible节点，确保主节点选举时能够形成多数派。



**Q：ES的写入流程是什么样的？**
A：ES写入数据的流程如下：客户端发送写请求到协调节点，协调节点根据文档ID通过哈希计算路由到具体的主分片，然后将写请求转发给该主分片所在的数据节点。主分片先执行写操作（比如文档新增、更新或删除），操作成功后再将该写请求并行发送给所有副本分片。副本分片完成写入后返回确认，最后协调节点将写入结果返回给客户端。



**Q：发请求首先是发到哪个节点上的？**
A：写请求最初是发送到协调节点（通常是集群中任意一个节点），协调节点接收到请求后会根据文档ID决定写入哪个主分片，然后再将请求路由到对应的数据节点执行写操作。



**Q：如果发起一个写请求，写请求都会到主节点上吗？**
A：不是所有写请求都发到主节点。这里的“主节点”是指负责集群状态的Master Node，而写请求会被路由到负责该分片的“主分片”所在的数据节点。所以写入操作是由主分片处理的，并不需要经过集群的主节点。



**Q：只要写一个主分片成功后，请求就结束了吗？**
A：不是，主分片写入成功后，还会将写操作同步到所有副本分片。当所有副本分片都确认成功写入后，请求才算真正完成。除非客户端显式设置了写一致性级别（如`wait_for`或`quorum`），否则默认是等所有副本写完后才返回成功。



**Q：副本分片是否需要保证完全写入？**
A：默认情况下是需要的。ES在主分片写入成功后，会同步写入到所有副本分片，只有当所有副本都成功写入后，才会向客户端返回成功响应。如果副本分片写入失败，ES会重试或者报错。通过一致性参数也可以调整是否等待副本写入完成。



**Q：ES是最终一致性还是强一致性？**
A：ES是最终一致性模型。写操作会在主分片和副本分片之间异步复制，因此在副本写入完成之前，查询可能读不到最新写入的数据。但ES允许通过刷新（refresh）等机制提高查询的一致性，也可以通过设置一致性参数控制写操作的确认策略，从而接近强一致性的效果。



**Q：ES的分页了解吗？**
A：ES默认使用`from + size`方式分页，这种方式适用于数据量较小的分页场景，但对于深度分页性能较差，因为每次查询都需要跳过大量文档，会增加内存和CPU的消耗，严重时还可能触发search context被清除。



**Q：如何实现深度翻页？**
A：为了高效实现深度翻页，ES推荐使用`search_after`或`scroll`机制。`search_after`基于上一次结果的排序值向后继续查询，适合实时性要求高的场景；`scroll`则适用于一次性拉取大量数据，比如数据导出或批量处理，查询期间数据一致但不适用于实时搜索场景。



**Q： QPS多少？有多少台服务实例？**

A：峰值的话应该是有3000多，在新疆喀什那边的话是有一个集中式的边缘服务，在武汉这边的话一般是一个服务，有两个服务实例做负载均衡。



#### 在实习中学到了什么？

在科大讯飞的这段实习经历给了我非常宝贵的成长：

首先，我深刻理解了分布式系统在实际业务场景中的应用。新疆与武汉之间的距离创造了一个真实的高延迟环境，这让我不得不思考如何优化网络传输、如何设计边缘计算架构。这不是书本上的理论知识，而是真实环境下的工程挑战。

其次，我学会了如何应对复杂业务逻辑。特别是在处理各种科目试卷的解析问题时，设计模式从抽象概念变成了解决实际问题的工具。策略模式和工厂模式的运用让我体会到好的架构设计对代码可维护性和扩展性的巨大价值。

最后，我学到了与团队协作的能力。跟随mentor学习，与AI部门、前端团队对接，让我明白了清晰沟通和接口约定的重要性。



#### 实习项目与自己做项目的区别？

最大的区别在于复杂度和真实性：

实习项目面临真实的用户和环境限制。新疆地区的网络状况、学校实际教学需求这些都不是自己做项目时能模拟的。当你知道有成千上万的学生和老师要依赖你的系统进行日常教学，责任感完全不同。

其次是规模和协作。自己做项目通常是小型的、独立的系统；而在实习中，我们的中间层需要与前端、AI评测系统、课后服务等多个子系统交互，这种复杂的依赖关系和团队协作是个人项目很难体验到的。

第三是技术选型的考量不同。在个人项目中，我可能会选择最新、最酷的技术；但在企业环境，我们需要考虑稳定性、可维护性和团队熟悉度等因素。比如使用成熟的Spring Cloud而非最新框架，使用Groovy脚本而非硬编码的规则引擎，都是基于实际情况的权衡。

最后，实习项目更注重业务价值。我不只是在写代码，而是在解决教育信息化的实际问题。这让我理解了技术是服务于业务的工具，而不是目的本身。





#### 为什么要自研，不用成熟的实现？请说说你研发的组件和dynamic-tp组件、hippo4j组件的优势是什么？

接入新的组件，尤其是这种包含控制台的组件，需要考虑公司自身的情况，比如申请部署资源是否方便，是否需要接入已有的账号体系。
通常自研的小组件唯一的优势就是足够轻量级而且快速，并且契合自己的业务。引入的组件由于版本等问题多多少少有些麻烦。



#### 你说说难点和亮点是什么？

难点可能没有因为总体代码量其实不是很多，我认为更多的是体现你善于发现问题解决问题的工作方法和态度。并在引入解决方案的同时，也有能力调研行业已有方案，分析优劣势，立项开搞。



#### 对AI工具的看法？

嗯，早期我对AI工具的看法，22年年底openAI的ChatGPT到今年年初爆火的deep seek R1当时我个人的感觉更像是它是一个辅助工具，因为它相对于来说我研究生生活包括我发的论文以及实际上，Java方面的学习这些工具都提供了很大的帮助，所以我早期对他的看法就是像是一种工具来看，然后找出来ai编程的话比如说idea我最常用的集成的是阿里的同意林码组件，它能进行一些灰色的提示，然后我按一下退部件能就能进行应用，但是我觉得他的上下文理解能力还是有限的所以我还是觉得它是一种辅助编程的工具，但是直到我使用了一些AI agent典型的就是现在的cursor AI编程工具它和之前的那些对话大模型来说的话，我第一感觉就是它的工具性非常强，它能创建文件修改文件，我口述的要求，比如说我常用的，它好像现在版本有三种模式，第一是agent为代理是最功能最全的模式，既可以问答也可以进行修改，根据要求，第2种是ask模式好像他这种模式的话就没有修改权限，我一般是用来他解读一个陌生的项目，还有就是为现在项目提供一些优化建议， 第3种的话edit专注于编辑也就是修改文件代码执行命令端指令。真的让我感觉到现在大模型ai作为生产力工具是可以替代一些部分人的操作，现在是2025年，像22年年底那时候我记得也就是我考研那年chatgpt横空出世，然后cursor我记得也是24年年底出现的，然后到现在的最新的版本大模型发展过去了两年半，体验感觉非常的强力，工作效率大大提升，预计未来5年，可能像ai编程ai绘画这种工具不仅也是提高工作效率，但从工具来看，实际上他还能作为一种虚拟的劳动者来进行执行业务，这就是我对于他现在的看法，也就是用一种展望的思路。



#### 你提到使用了cursor你用到他做了什么项目？用什么promt？

我最初的使用情况是，其实主要是对我的科研，一般就是用来就是读论文的时候会看一些顶盘顶会，然后他论文代码开源就从github下拉下来，利用cursor超强的全局感知，来进行解读剪模块的作用，然后的话尝试将一些有效的模块添加到我自己的代码之中，提升实验效果，后来的话，都考虑到我只有一个单独的短链接项目其实有点不太够，然后我刚好有个做一个新的Java项目的打算，然后思来想去的话，感觉多线程编程是一个非常频繁的方向，但是我在学习那些基础知识的时候，比如说经常提到什么io密集型cpu密集型任务它的参数设置，比如说加一之类的，但是后面有备注，这只是经验之选，实际情况非常复杂，所以我认为实际上的性能值它应该就是不能固定的设置，然后刚好就学习了一些文章，拜读了咱们美团技术团队的动态线程池技术博客，然后我就想到了做一个新的组件项目也就是动态线程池，对于整体的思路而言也是cursor给我的，然后我实现了一些简单的功能，比如说县城池数据上报啊，触发器执行定时上报这类功能，然后利用cusor的agent模式进行优化，典型的一个案例就是有一个定时任务持续的进行上报现成池的信息，然后我的一个简单处理就是非常简单粗暴也就是利用Redisoon的Rlist创建拉取，然后直接删除，然后再进行添加主要是为了防止重复上报，然后导致数据重复问题。然后我就利用cusor的agent模式提出问题让它进行优化，然后摆明这个性能很差，随后的话cusor功能非常强大直接使用了RMAP是利用哈希表的唯一性来进行，防止重复，而不需要每次直接清理整个，然后再进行添加，完美的达到了我的预期，然后之后的话有了基本功能，我就让他展开的去写了。

一开始我的promt都是一些比较宽泛性的，我记得我描述的非常多然后让他在原来admin（也就是县城池在线更改服务提供前端空出来使用）单独的实现一大部分功能，就是关于呃数据的采集以及监控像拒绝策略数一些核心的指标监控然后告警邮件告警，飞书告警之类的，然后可能是因为我的指令特别的宽泛，实际上还得出了不太好的效果。但是总结结果就两个

第一cursor编程出现一部分错误，但是随后让他进行修改错误时完美的进行修改了，但是我感觉核实的prompt还是很重要的，因为我用的是免费版哈哈哈哈。

第二它会尝试自己实现一大堆监控功能，而不是使用一些现有的工具stater，比如说普罗米修斯加上grfaan实现部分监控和告警。

所以在随后的话经过这个教训，我也就是在之前的checkpoint进行了比较精细化的也就不是特别宽泛的首先根据我当前的需求进行拆分然后拆分的话一步一步进行来，然后再进行现在的工友的一些大模型工具，比如说我现在比较常用的就是 claude3.7 sonnet将我的初步描述让他进行分析为并转写为cursor工具合适的promt然后再进行直线，我感觉效果就比原来好的多。





#### 在当今这个AI这个时代完全替代人的工作，你觉得有什么优势？

我觉得首先主要两点，首先第1点的话肯定是不能固步自封的，一个人必须持续的学习像这些ai编程这种新工具不能排斥憎恨，也就是说什么减少我们工作，然后拒绝去学习，应该很好奇去学习，像打个不恰当的比方早期的单体服务到前几年流行的微服务解决方案再到现在的云原生解决方案每一种解决方案都是顺应时代的人，要适应环境，然后持续的学习新的东西，的道理就是早期的编程到ai工具，现在编程应该更加适应它学习它，然后明白更好的使用它，在现在目前的版本，虽然我个人感觉ai编程肯定是大势所趋，但是中间还是有个相互交融的过程，慢慢进行过渡所以对这一环节来说，我觉得学习ai对于提高自己的竞争力非常有帮助。

2点的话可能是一个比较虚的东西，但是确实是我的肺腑之言，就是你要对一个职业有热爱，也就是对编程还有对后端开发这个这个职业有比较深的热爱有理想你才能学得下去，而不是等简简单单的当成一口饭来吃这个玩意儿，所以我觉得我第2个优势的话就是在于我如果勤奋以及对事物感兴趣，然后对事物底层理解也感兴趣，然后愿意去学习编程相关的东西也愿意去学习新的东西。





#### 一个完全不太了解的开发者使用AI就能开发成一个很好的东西吗？还是说利用AI才行？

就我个人的理解而言，当前cursor这类ai编程工具或者其他一方面aiagent工具虽然提高了强大的功能，但是你没有合适的那种引导词，也就是prompt无法发挥它完成的性能，而你要有相关in的prompt，也就是计算机知识储备的话，我觉得你还要首先要有相应的知识储备才行完全不太了解的开发者使用ai编程的话，可能最后效果不尽人意，虽然可能也会开发成一个很好的产品，但是我觉得一个相对于来说经验更丰富的，比如说你的这个层次来说的话，它肯定能更好地把握项目整体，所以我觉得现在目前的话学习心的只是ai和一些基本的基础知识以及项目经验也是非常重要的，对于目前的开发者来说。







